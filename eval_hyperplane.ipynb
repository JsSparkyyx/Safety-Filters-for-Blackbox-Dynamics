{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.Safe2Unsafe import DeepAccidentDataset\n",
    "from method.dynamics import HyperplaneEncoder\n",
    "from method.barriers import DiscriminatingHyperplane\n",
    "from method.trainers import HyperplaneTrainer\n",
    "import torch\n",
    "import time\n",
    "import pytorch_lightning as pl\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DeepAccidentDataset(train_batch_size=32,val_batch_size=32,num_workers=16)\n",
    "data.setup()\n",
    "train_dataloader = data.train_dataloader()\n",
    "test_dataloader = data.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HyperplaneTrainer(\n",
       "  (model): HyperplaneEncoder(\n",
       "    (encoder): ViTAttentionEncoder(\n",
       "      (ViT): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU()\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=774, out_features=16, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (linear): Linear(in_features=34, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (barrier): DiscriminatingHyperplane(\n",
       "    (cbf): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=1024, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=1024, out_features=3, bias=True)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim = 16\n",
    "barrier = DiscriminatingHyperplane(2,latent_dim=latent_dim)\n",
    "# model = HyperplaneEncoder(2,\"cuda\",model=\"google/vit-base-patch16-224\",latent_dim=latent_dim)\n",
    "model = HyperplaneEncoder(2,\"cuda\",model=\"vc1\",latent_dim=latent_dim)\n",
    "# model = HyperplaneEncoder(2,\"cuda\",model=\"openai/clip-vit-base-patch16\",latent_dim=latent_dim)\n",
    "# model = HyperplaneEncoder(2,\"cuda\",model=\"resnet\",latent_dim=latent_dim)\n",
    "trainer = HyperplaneTrainer(model,barrier)\n",
    "checkpoint = torch.load(\"/root/tf-logs/DiscriminatingHyperplane/version_4/checkpoints/last.ckpt\")\n",
    "trainer.load_state_dict(checkpoint['state_dict'])\n",
    "trainer.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.54it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.01it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.01it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.02it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.46it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.74it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.09it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.91it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.18it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.76it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.03it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "b_all = []\n",
    "label_all = []\n",
    "trainer.eval()\n",
    "for idx, (i,u,label) in enumerate(test_dataloader):\n",
    "    i, u = i.to(\"cuda\"), u.to(\"cuda\")\n",
    "    x = trainer.model.simulate(i,u)\n",
    "    a,b = trainer.barrier(x)\n",
    "    value = torch.einsum(\"btc,btc->bt\",a,u) + b\n",
    "    b_all.append((value < 0).cpu())\n",
    "    label_all.append(label.squeeze(-1))\n",
    "import numpy as np\n",
    "bs = torch.cat(b_all)\n",
    "labels = torch.cat(label_all)\n",
    "results = torch.cat([bs,labels.unsqueeze(-1)],dim=-1).detach().numpy()\n",
    "np.savetxt(\"./results_hyperplane_vc1.txt\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9958940397350994 0.017777777777777778\n"
     ]
    }
   ],
   "source": [
    "results = np.loadtxt(\"./results_hyperplane_vc1.txt\")\n",
    "regular = results[results[:,-1] == 0,:-1]\n",
    "collision = results[results[:,-1] == 1,:-1]\n",
    "acc_regular = (regular <= 0).mean()\n",
    "acc_collision = (collision > 0).mean()\n",
    "print(acc_regular,acc_collision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

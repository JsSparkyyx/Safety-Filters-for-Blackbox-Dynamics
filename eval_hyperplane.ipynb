{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.Safe2Unsafe import DeepAccidentDataset\n",
    "from method.dynamics import HyperplaneEncoder\n",
    "from method.barriers import DiscriminatingHyperplane\n",
    "from method.trainers import HyperplaneTrainer\n",
    "import torch\n",
    "import time\n",
    "import pytorch_lightning as pl\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DeepAccidentDataset(train_batch_size=32,val_batch_size=32,num_workers=16)\n",
    "data.setup()\n",
    "train_dataloader = data.train_dataloader()\n",
    "test_dataloader = data.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/tf-logs/DiscriminatingHyperplane/version_0/checkpoints/last.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6608/4196320541.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# model = HyperplaneEncoder(2,\"cuda\",model=\"resnet\",latent_dim=latent_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHyperplaneTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbarrier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/root/tf-logs/DiscriminatingHyperplane/version_0/checkpoints/last.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/tf-logs/DiscriminatingHyperplane/version_0/checkpoints/last.ckpt'"
     ]
    }
   ],
   "source": [
    "latent_dim = 16\n",
    "barrier = DiscriminatingHyperplane(2,latent_dim=latent_dim)\n",
    "model = HyperplaneEncoder(2,\"cuda\",model=\"google/vit-base-patch16-224\",latent_dim=latent_dim)\n",
    "# model = HyperplaneEncoder(2,\"cuda\",model=\"vc1\",latent_dim=latent_dim)\n",
    "# model = HyperplaneEncoder(2,\"cuda\",model=\"openai/clip-vit-base-patch16\",latent_dim=latent_dim)\n",
    "# model = HyperplaneEncoder(2,\"cuda\",model=\"resnet\",latent_dim=latent_dim)\n",
    "trainer = HyperplaneTrainer(model,barrier)\n",
    "checkpoint = torch.load(\"/root/tf-logs/DiscriminatingHyperplane/version_0/checkpoints/last.ckpt\")\n",
    "trainer.load_state_dict(checkpoint['state_dict'])\n",
    "trainer.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.54it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.01it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.01it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.02it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.46it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.55it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.74it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.09it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.91it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.18it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.76it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.37it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.03it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.04it/s]\n"
     ]
    }
   ],
   "source": [
    "b_all = []\n",
    "label_all = []\n",
    "trainer.eval()\n",
    "for idx, (i,u,label) in enumerate(test_dataloader):\n",
    "    i, u = i.to(\"cuda\"), u.to(\"cuda\")\n",
    "    x = trainer.model.simulate(i,u)\n",
    "    a,b = trainer.barrier(x)\n",
    "    value = torch.einsum(\"btc,btc->bt\",a,u) + b\n",
    "    b_all.append((value < 0).cpu())\n",
    "    label_all.append(label.squeeze(-1))\n",
    "import numpy as np\n",
    "bs = torch.cat(b_all)\n",
    "labels = torch.cat(label_all)\n",
    "results = torch.cat([bs,labels.unsqueeze(-1)],dim=-1).detach().numpy()\n",
    "np.savetxt(\"./results_hyperplane_vc1.txt\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9958940397350994 0.017777777777777778\n"
     ]
    }
   ],
   "source": [
    "results = np.loadtxt(\"./results_hyperplane_vc1.txt\")\n",
    "regular = results[results[:,-1] == 0,:-1]\n",
    "collision = results[results[:,-1] == 1,:-1]\n",
    "acc_regular = (regular <= 0).mean()\n",
    "acc_collision = (collision > 0).mean()\n",
    "print(acc_regular,acc_collision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from traj_len_15 import DeepAccidentDataset\n",
    "from data.Safe2Unsafe import DeepAccidentDataset\n",
    "from method.ViT import InDCBFTrainer, InDCBFController, Barrier\n",
    "import torch\n",
    "import time\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DeepAccidentDataset(train_batch_size=32,val_batch_size=32,num_workers=16)\n",
    "data.setup()\n",
    "train_dataloader = data.train_dataloader()\n",
    "test_dataloader = data.val_dataloader()\n",
    "barrier = Barrier(2,512)\n",
    "model = InDCBFController(2,\"cuda\",model=\"google/vit-base-patch16-224\",latent_dim=512)\n",
    "checkpoint = torch.load(\"/root/tf-logs/BarrierClassifier/version_1/checkpoints/epoch=80-step=16037.ckpt\")\n",
    "trainer = InDCBFTrainer(model,barrier)\n",
    "trainer.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (i_all,u_all,label) in enumerate(test_dataloader):\n",
    "    if label.sum()>0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n"
     ]
    }
   ],
   "source": [
    "x_init = torch.zeros(1,512).to('cuda')\n",
    "model = trainer.model.to(\"cuda\")\n",
    "barrier = trainer.barrier.to(\"cuda\")\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0508374  -4.17871857] tensor([ 0.0508, -4.1787], device='cuda:0')\n",
      "[ 0.04569366 -3.84402585] tensor([ 0.0457, -3.8440], device='cuda:0')\n",
      "[ 0.04593947 -3.83066034] tensor([ 0.0459, -3.8307], device='cuda:0')\n",
      "[ 0.04822314 -3.99490833] tensor([ 0.0482, -3.9949], device='cuda:0')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for dimension 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1986/3665318544.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# u, result = model(i[0,1].unsqueeze(0),u[0,0].unsqueeze(0),x_p,u[0,0].unsqueeze(0),barrier)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbarrier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mx_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for dimension 0 with size 5"
     ]
    }
   ],
   "source": [
    "imgs = i_all[10].to(\"cuda\")\n",
    "us = u_all[10].to(\"cuda\")\n",
    "x_p = model.encoder(imgs[0,:].unsqueeze(0),x_init,us[0].unsqueeze(0))\n",
    "for i in range(1,15):\n",
    "# u, result = model(i[0,1].unsqueeze(0),u[0,0].unsqueeze(0),x_p,u[0,0].unsqueeze(0),barrier)\n",
    "    v, result, prob = model(imgs[i].unsqueeze(0),us[i-1].unsqueeze(0),x_p,us[i].unsqueeze(0),barrier)\n",
    "    x_p = model.encoder(imgs[i,:].unsqueeze(0),x_p,us[i-1].unsqueeze(0))\n",
    "    print(v.value,us[i])\n",
    "# print(us[0])\n",
    "# print(us[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2506.46806297  -386.10911042]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for dimension 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1986/32151628.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for dimension 0 with size 5"
     ]
    }
   ],
   "source": [
    "print(v.value)\n",
    "print(us[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.000443073,\n",
       " array([ 0.00862157, -0.03043856], dtype=float32),\n",
       " array([0.0392131], dtype=float32))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_ref = us[1].unsqueeze(0)\n",
    "u_p = us[1].unsqueeze(0)\n",
    "i = imgs[1].unsqueeze(0)\n",
    "import cvxpy as cp\n",
    "u_ref = u_ref.view(-1).cpu().numpy()\n",
    "x = model.encoder(i,x_p,u_p)\n",
    "f, g = model.ode(x)\n",
    "f = f.view(-1).detach().cpu().numpy()\n",
    "g = g.view(-1,2).detach().cpu().numpy()\n",
    "b = barrier(x)\n",
    "d_b = torch.autograd.grad(b,x,retain_graph=True)[0]\n",
    "b = b.view(-1).detach().cpu().numpy()\n",
    "x = x.view(-1).detach().cpu().numpy()\n",
    "d_b = d_b.view(-1).cpu().numpy()\n",
    "u = cp.Variable(u_ref.shape)\n",
    "t1 = d_b @ f\n",
    "t2 = d_b @ g \n",
    "t3 = b/15\n",
    "objective = cp.Minimize(cp.sum_squares(u - u_ref))\n",
    "constraints = [(t1+t2@u+t3)>=0]\n",
    "prob = cp.Problem(objective, constraints)\n",
    "result = prob.solve()\n",
    "t1, t2, t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0023901234,\n",
       " array([-0.00282371, -0.01853349], dtype=float32),\n",
       " array([-0.0297253], dtype=float32))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:09<00:00,  1.40it/s]\n",
      "100%|██████████| 14/14 [01:18<00:00,  5.59s/it]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.62it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.62it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.72it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.71it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.71it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.71it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.71it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.71it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.70it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.71it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.69it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.69it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.70it/s]\n"
     ]
    }
   ],
   "source": [
    "b_all = []\n",
    "label_all = []\n",
    "for idx, (i,u,label) in enumerate(test_dataloader):\n",
    "    i, u = i.to(\"cuda\"), u.to(\"cuda\")\n",
    "    x,x_tide = model.simulate(i,u,dt=0.1,window_size=1,rtol=5e-6)\n",
    "    b = barrier(x).squeeze(-1)\n",
    "    b_all.append(b.cpu())\n",
    "    label_all.append(label.squeeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "bs = torch.cat(b_all)\n",
    "labels = torch.cat(label_all)\n",
    "results = torch.cat([bs,labels.unsqueeze(-1)],dim=-1).detach().numpy()\n",
    "np.savetxt(\"./results.txt\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = results[:,:-1]\n",
    "label = results[:,-1]\n",
    "mask = np.zeros_like(b)\n",
    "mask[label == 1,-5:] = 1\n",
    "b_safe = b[label == 0]\n",
    "b_unsafe = b[label == 1,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe 1.0 -0.67952687 0.97396356 0.14432254\n",
      "Unsafe 1.0 -0.6665393 0.91301495 0.343813\n"
     ]
    }
   ],
   "source": [
    "max_safe = b_safe.max()\n",
    "min_safe = b_safe.min()\n",
    "mean_safe = b_safe.mean()\n",
    "std_safe = b_safe.std()\n",
    "max_unsafe = b_unsafe.max()\n",
    "min_unsafe = b_unsafe.min()\n",
    "mean_unsafe = b_unsafe.mean()\n",
    "std_unsafe = b_unsafe.std()\n",
    "print(\"Safe\", max_safe, min_safe, mean_safe, std_safe)\n",
    "print(\"Unsafe\", max_unsafe, min_unsafe, mean_unsafe, std_unsafe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:09<00:00,  1.55it/s]\n",
      "100%|██████████| 14/14 [00:07<00:00,  1.82it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.54it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.51it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.59it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.59it/s]\n",
      "100%|██████████| 14/14 [00:06<00:00,  2.12it/s]\n",
      "100%|██████████| 14/14 [00:09<00:00,  1.54it/s]\n",
      "100%|██████████| 14/14 [00:06<00:00,  2.12it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.58it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.63it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.66it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.66it/s]\n",
      "100%|██████████| 14/14 [00:05<00:00,  2.35it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  3.07it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.65it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.12it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.65it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.25it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.07it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.08it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.03it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.09it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.66it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.19it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.66it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.73it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.25it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.94it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.09it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.03it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.02it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.06it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.21it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.00it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.06it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.04it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.01it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.97it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.99it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.97it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.20it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.09it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.04it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.64it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.85it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.14it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.09it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.22it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.11it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.08it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.64it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.16it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.08it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.04it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.00it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.11it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.15it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.07it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.99it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.06it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.14it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.19it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.23it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.06it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.20it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.07it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.15it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.08it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.12it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.15it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.15it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.15it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.99it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.00it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.01it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.00it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.08it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.96it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.13it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.31it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.05it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.98it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.14it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  3.98it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.11it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.04it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.10it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.03it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.11it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.00it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.11it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.09it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.04it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.64it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  3.07it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  3.34it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.57it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.56it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.69it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.67it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.69it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.67it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.69it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.66it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.69it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.67it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.62it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.66it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.68it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.54it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.67it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.67it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.69it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.67it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.70it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.66it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.70it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.66it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.69it/s]\n"
     ]
    }
   ],
   "source": [
    "b_all_train = []\n",
    "label_all_train = []\n",
    "for idx, (i,u,label) in enumerate(train_dataloader):\n",
    "    i, u = i.to(\"cuda\"), u.to(\"cuda\")\n",
    "    x,x_tide = model.simulate(i,u,dt=0.1,window_size=1,rtol=5e-6)\n",
    "    b = barrier(x).squeeze(-1)\n",
    "    b_all_train.append(b.cpu())\n",
    "    label_all_train.append(label.squeeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "bs_train = torch.cat(b_all_train)\n",
    "labels_train = torch.cat(label_all_train)\n",
    "results_train = torch.cat([bs_train,labels_train.unsqueeze(-1)],dim=-1).detach().numpy()\n",
    "np.savetxt(\"./results_train.txt\",results_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = results_train[:,:-1]\n",
    "label = results_train[:,-1]\n",
    "mask = np.zeros_like(b)\n",
    "mask[label == 1,-5:] = 1\n",
    "b_safe = b[label == 0]\n",
    "b_unsafe = b[label == 1,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe 1.0 -0.60138047 0.9851279 0.0887461\n",
      "Unsafe 0.9999999 -0.7876854 0.76094234 0.52417785\n"
     ]
    }
   ],
   "source": [
    "max_safe = b_safe.max()\n",
    "min_safe = b_safe.min()\n",
    "mean_safe = b_safe.mean()\n",
    "std_safe = b_safe.std()\n",
    "max_unsafe = b_unsafe.max()\n",
    "min_unsafe = b_unsafe.min()\n",
    "mean_unsafe = b_unsafe.mean()\n",
    "std_unsafe = b_unsafe.std()\n",
    "print(\"Safe\", max_safe, min_safe, mean_safe, std_safe)\n",
    "print(\"Unsafe\", max_unsafe, min_unsafe, mean_unsafe, std_unsafe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.Safe2Unsafe import DeepAccidentDataset\n",
    "from method.ResNet import InDCBFTrainer, InDCBFController, Barrier\n",
    "import torch\n",
    "import time\n",
    "import pytorch_lightning as pl\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DeepAccidentDataset(train_batch_size=32,val_batch_size=32,num_workers=16)\n",
    "data.setup()\n",
    "train_dataloader = data.train_dataloader()\n",
    "test_dataloader = data.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InDCBFTrainer(\n",
       "  (model): InDCBFController(\n",
       "    (encoder): Encoder(\n",
       "      (ResNet): ResNet(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=1006, out_features=16, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (linear): Linear(in_features=34, out_features=16, bias=True)\n",
       "    )\n",
       "    (ode): NeuralODE(\n",
       "      (ode_f): Sequential(\n",
       "        (0): Linear(in_features=16, out_features=1024, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=1024, out_features=16, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (ode_g): Sequential(\n",
       "        (0): Linear(in_features=16, out_features=1024, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=1024, out_features=32, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (barrier): Barrier(\n",
       "    (cbf): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim = 16\n",
    "barrier = Barrier(2,latent_dim=latent_dim)\n",
    "model = InDCBFController(2,\"cuda\",model=\"resnet50\",latent_dim=latent_dim)\n",
    "# model = InDCBFController(2,\"cuda\",model=\"google/vit-base-patch16-224\",latent_dim=latent_dim)\n",
    "# model = InDCBFController(2,\"cuda\",model=\"openai/clip-vit-base-patch16\",latent_dim=latent_dim)\n",
    "checkpoint = torch.load(\"/root/tf-logs/InDCBF/version_2/checkpoints/last.ckpt\")\n",
    "trainer = InDCBFTrainer(model,barrier)\n",
    "trainer.load_state_dict(checkpoint['state_dict'])\n",
    "trainer.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InDCBFTrainer(\n",
       "  (model): InDCBFDynamics(\n",
       "    (vae): ViTEncoder(\n",
       "      (ViT): CLIPVisionModel(\n",
       "        (vision_model): CLIPVisionTransformer(\n",
       "          (embeddings): CLIPVisionEmbeddings(\n",
       "            (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "            (position_embedding): Embedding(197, 768)\n",
       "          )\n",
       "          (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder): CLIPEncoder(\n",
       "            (layers): ModuleList(\n",
       "              (0): CLIPEncoderLayer(\n",
       "                (self_attn): CLIPAttention(\n",
       "                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): CLIPMLP(\n",
       "                  (activation_fn): QuickGELUActivation()\n",
       "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (1): CLIPEncoderLayer(\n",
       "                (self_attn): CLIPAttention(\n",
       "                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): CLIPMLP(\n",
       "                  (activation_fn): QuickGELUActivation()\n",
       "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (2): CLIPEncoderLayer(\n",
       "                (self_attn): CLIPAttention(\n",
       "                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): CLIPMLP(\n",
       "                  (activation_fn): QuickGELUActivation()\n",
       "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (3): CLIPEncoderLayer(\n",
       "                (self_attn): CLIPAttention(\n",
       "                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): CLIPMLP(\n",
       "                  (activation_fn): QuickGELUActivation()\n",
       "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (4): CLIPEncoderLayer(\n",
       "                (self_attn): CLIPAttention(\n",
       "                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): CLIPMLP(\n",
       "                  (activation_fn): QuickGELUActivation()\n",
       "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (5): CLIPEncoderLayer(\n",
       "                (self_attn): CLIPAttention(\n",
       "                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): CLIPMLP(\n",
       "                  (activation_fn): QuickGELUActivation()\n",
       "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (6): CLIPEncoderLayer(\n",
       "                (self_attn): CLIPAttention(\n",
       "                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): CLIPMLP(\n",
       "                  (activation_fn): QuickGELUActivation()\n",
       "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (7): CLIPEncoderLayer(\n",
       "                (self_attn): CLIPAttention(\n",
       "                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): CLIPMLP(\n",
       "                  (activation_fn): QuickGELUActivation()\n",
       "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (8): CLIPEncoderLayer(\n",
       "                (self_attn): CLIPAttention(\n",
       "                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): CLIPMLP(\n",
       "                  (activation_fn): QuickGELUActivation()\n",
       "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (9): CLIPEncoderLayer(\n",
       "                (self_attn): CLIPAttention(\n",
       "                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): CLIPMLP(\n",
       "                  (activation_fn): QuickGELUActivation()\n",
       "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (10): CLIPEncoderLayer(\n",
       "                (self_attn): CLIPAttention(\n",
       "                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): CLIPMLP(\n",
       "                  (activation_fn): QuickGELUActivation()\n",
       "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (11): CLIPEncoderLayer(\n",
       "                (self_attn): CLIPAttention(\n",
       "                  (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): CLIPMLP(\n",
       "                  (activation_fn): QuickGELUActivation()\n",
       "                  (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=16, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (linear): Linear(in_features=34, out_features=16, bias=True)\n",
       "    )\n",
       "    (ode): NeuralODE(\n",
       "      (ode_f): Sequential(\n",
       "        (0): Linear(in_features=16, out_features=1024, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=1024, out_features=16, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (ode_g): Sequential(\n",
       "        (0): Linear(in_features=16, out_features=1024, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=1024, out_features=32, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (barrier): InDCBFBarrier(\n",
       "    (cbf): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (7): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from method.dynamics import InDCBFDynamics\n",
    "from method.barriers import InDCBFBarrier\n",
    "from method.trainers import InDCBFTrainer\n",
    "latent_dim = 16\n",
    "barrier = InDCBFBarrier(2,latent_dim=latent_dim)\n",
    "model = InDCBFDynamics(2,\"cuda\",model=\"openai/clip-vit-base-patch16\",latent_dim=latent_dim)\n",
    "# model = InDCBFDynamics(2,\"cuda\",model=\"google/vit-base-patch16-224\",latent_dim=latent_dim)\n",
    "trainer = InDCBFTrainer(model,barrier)\n",
    "checkpoint = torch.load(\"/root/tf-logs/InDCBFWORec/version_1/checkpoints/last.ckpt\")\n",
    "trainer.load_state_dict(checkpoint['state_dict'])\n",
    "trainer.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.18it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.98it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.98it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.13it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.95it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.83it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.66it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.40it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.97it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.03it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.12it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.74it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.27it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.26it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.69it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.30it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.28it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.31it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.32it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.34it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.33it/s]\n"
     ]
    }
   ],
   "source": [
    "b_all = []\n",
    "label_all = []\n",
    "# trainer.eval()\n",
    "for idx, (i,u,label) in enumerate(test_dataloader):\n",
    "    i, u = i.to(\"cuda\"), u.to(\"cuda\")\n",
    "    x,x_tide = trainer.model.simulate(i,u,dt=0.1,window_size=1,rtol=5e-6)\n",
    "    b = trainer.barrier(x).squeeze(-1)\n",
    "    b_all.append(b.cpu())\n",
    "    label_all.append(label.squeeze(-1))\n",
    "import numpy as np\n",
    "bs = torch.cat(b_all)\n",
    "labels = torch.cat(label_all)\n",
    "results = torch.cat([bs,labels.unsqueeze(-1)],dim=-1).detach().numpy()\n",
    "np.savetxt(\"./results_clip_multi_rep.txt\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.12it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[32, 5, 16, 2]' is invalid for input of size 30720",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3115/1196529160.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_safe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mgu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'btha,bta->bth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mascent_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bth,bth->bt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_b_safe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mb_ascent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mascent_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_safe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[32, 5, 16, 2]' is invalid for input of size 30720"
     ]
    }
   ],
   "source": [
    "b_all_ascent = []\n",
    "b_all_descent = []\n",
    "label_all = []\n",
    "# trainer.eval()\n",
    "for idx, (i,u,label) in enumerate(test_dataloader):\n",
    "    label = label.squeeze(dim=-1)\n",
    "    i, u = i.to(\"cuda\"), u.to(\"cuda\")\n",
    "    x,x_tide = trainer.model.simulate(i,u,dt=0.1,window_size=1,rtol=5e-6)\n",
    "    x_safe = x[label == 0]\n",
    "    x_unsafe = x[label == 1]\n",
    "    # x_safe.requires_grad = True\n",
    "    # x_unsafe.requires_grad = True\n",
    "    b_safe = trainer.barrier(x_safe)\n",
    "    b_unsafe = trainer.barrier(x_unsafe)\n",
    "\n",
    "    d_b_safe = torch.autograd.grad(b_safe.mean(),x_safe,retain_graph=True)[0]\n",
    "    with torch.no_grad():\n",
    "        f, g = trainer.model.ode(x_safe)\n",
    "    gu = torch.einsum('btha,bta->bth',g.view(g.shape[0],g.shape[1],f.shape[-1],2),u[label == 0])\n",
    "    ascent_value = torch.einsum('bth,bth->bt', d_b_safe, (f + gu))\n",
    "    b_ascent = ascent_value.unsqueeze(-1) + b_safe\n",
    "\n",
    "    d_b_unsafe = torch.autograd.grad(b_unsafe.mean(),x_unsafe,retain_graph=True)[0]\n",
    "    with torch.no_grad():\n",
    "        f, g = trainer.model.ode(x_unsafe)\n",
    "    gu = torch.einsum('btha,bta->bth',g.view(g.shape[0],g.shape[1],f.shape[-1],2),u[label == 1])\n",
    "    descent_value = torch.einsum('bth,bth->bt', d_b_unsafe, (f + gu))\n",
    "    b_descent = descent_value.unsqueeze(-1) + b_unsafe\n",
    "\n",
    "    b_all_ascent.append(b_ascent.cpu())\n",
    "    b_all_descent.append(b_descent.cpu())\n",
    "    label_all.append(label)\n",
    "import numpy as np\n",
    "bsa = torch.cat(b_all_ascent)\n",
    "bsd = torch.cat(b_all_descent)\n",
    "labels = torch.cat(label_all)\n",
    "results1 = torch.cat([bsa.squeeze(-1),labels[labels == 0].unsqueeze(-1)],dim=-1).detach().numpy()\n",
    "results2 = torch.cat([bsd.squeeze(-1),labels[labels == 1].unsqueeze(-1)],dim=-1).detach().numpy()\n",
    "np.savetxt(\"./results_grad_asc_resnet.txt\",results1)\n",
    "np.savetxt(\"./results_grad_dsc_resnet.txt\",results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], device='cuda:0', size=(0, 5, 1), grad_fn=<TanhBackward0>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 1, but got NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3115/1912237640.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_unsafe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mgu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'btnha,btna->btnh'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdescent_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'btnh,btnh->bt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_b_unsafe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mb_descent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescent_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_unsafe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 1, but got NoneType"
     ]
    }
   ],
   "source": [
    "b_all_ascent = []\n",
    "b_all_descent = []\n",
    "label_all = []\n",
    "# trainer.eval()\n",
    "for idx, (i,u,label) in enumerate(test_dataloader):\n",
    "    label = label.squeeze(dim=-1)\n",
    "    i, u = i.to(\"cuda\"), u.to(\"cuda\")\n",
    "    x,x_tide = trainer.model.simulate(i,u,dt=0.1,window_size=1,rtol=5e-6)\n",
    "    x_safe = x[label == 0]\n",
    "    x_unsafe = x[label == 1]\n",
    "    # x_safe.requires_grad = True\n",
    "    # x_unsafe.requires_grad = True\n",
    "\n",
    "    b_safe = trainer.barrier(x_safe)\n",
    "    d_b_safe = torch.autograd.grad(b_safe.mean(),x_safe,retain_graph=True)[0]\n",
    "    with torch.no_grad():\n",
    "        f, g = trainer.model.ode(x_safe)\n",
    "    gu = torch.einsum('btnha,btna->btnh',g.view(g.shape[0],g.shape[1],g.shape[2],f.shape[-1],2),u[label == 0].unsqueeze(2).expand(-1,-1,g.shape[2],-1))\n",
    "    ascent_value = torch.einsum('btnh,btnh->bt', d_b_safe, (f + gu))\n",
    "    b_ascent = ascent_value.unsqueeze(-1) + b_safe\n",
    "\n",
    "    b_unsafe = trainer.barrier(x_unsafe)\n",
    "    print(b_unsafe)\n",
    "    d_b_unsafe = torch.autograd.grad(b_unsafe.mean(),x_unsafe,retain_graph=True,allow_unused=True)[0]\n",
    "    with torch.no_grad():\n",
    "        f, g = trainer.model.ode(x_unsafe)\n",
    "    gu = torch.einsum('btnha,btna->btnh',g.view(g.shape[0],g.shape[1],g.shape[2],f.shape[-1],2),u[label == 1].unsqueeze(2).expand(-1,-1,g.shape[2],-1))\n",
    "    descent_value = torch.einsum('btnh,btnh->bt', d_b_unsafe, (f + gu))\n",
    "    b_descent = descent_value.unsqueeze(-1) + b_unsafe\n",
    "\n",
    "    b_all_ascent.append(b_ascent.cpu())\n",
    "    b_all_descent.append(b_descent.cpu())\n",
    "    label_all.append(label)\n",
    "import numpy as np\n",
    "bsa = torch.cat(b_all_ascent)\n",
    "bsd = torch.cat(b_all_descent)\n",
    "labels = torch.cat(label_all)\n",
    "results1 = torch.cat([bsa.squeeze(-1),labels[labels == 0].unsqueeze(-1)],dim=-1).detach().numpy()\n",
    "results2 = torch.cat([bsd.squeeze(-1),labels[labels == 1].unsqueeze(-1)],dim=-1).detach().numpy()\n",
    "np.savetxt(\"./results_grad_asc_vit_multi_rep.txt\",results1)\n",
    "np.savetxt(\"./results_grad_dsc_vit_multi_rep.txt\",results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9585430463576159 0.5733333333333334\n"
     ]
    }
   ],
   "source": [
    "asc = np.loadtxt(\"./results_grad_asc_vit.txt\")[:,:-1]\n",
    "dsc = np.loadtxt(\"./results_grad_dsc_vit.txt\")[:,:-1]\n",
    "acc_regular = (asc > 0).mean()\n",
    "acc_collision = (dsc < 0).mean()\n",
    "print(acc_regular,acc_collision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.loadtxt(\"./results_clip_multi_rep.txt\")\n",
    "regular = results[results[:,-1] == 0,:-1]\n",
    "collision = results[results[:,-1] == 1,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9031788079470199 0.56\n"
     ]
    }
   ],
   "source": [
    "acc_regular = (regular > 0).mean()\n",
    "acc_collision = (collision < 0).mean()\n",
    "print(acc_regular,acc_collision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "from diffusers.models import AutoencoderKL\n",
    "vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "path = \"/root/DeepAccident/data/DeepAccident_data/type1_subtype1_accident/ego_vehicle/Camera_Front/Town01_type001_subtype0001_scenario00008\"\n",
    "img_name = \"{}_{:03d}.jpg\".format(\"Town01_type001_subtype0001_scenario00008\",1)\n",
    "img_path = os.path.join(path,img_name)\n",
    "img = read_image(img_path)/255\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),     \n",
    "        ])\n",
    "sample = transform(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = vae.encode(sample)['latent_dist'].mode()\n",
    "rec = vae.decoder(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "save_image(rec.data[0],\"./test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

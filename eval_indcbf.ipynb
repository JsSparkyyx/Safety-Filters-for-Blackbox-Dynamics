{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.Safe2Unsafe import DeepAccidentDataset\n",
    "from method.dynamics import InDCBFAttentionDynamics, InDCBFDynamics\n",
    "from method.barriers import InDCBFAttentionBarrier, InDCBFBarrier\n",
    "from method.trainers import InDCBFTrainer\n",
    "import torch\n",
    "import time\n",
    "import pytorch_lightning as pl\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DeepAccidentDataset(train_batch_size=32,val_batch_size=32,num_workers=16)\n",
    "data.setup()\n",
    "train_dataloader = data.train_dataloader()\n",
    "test_dataloader = data.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InDCBFTrainer(\n",
       "  (model): InDCBFDynamics(\n",
       "    (vae): ViTEncoder(\n",
       "      (ViT): ViTModel(\n",
       "        (embeddings): ViTEmbeddings(\n",
       "          (patch_embeddings): ViTPatchEmbeddings(\n",
       "            (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (encoder): ViTEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0): ViTLayer(\n",
       "              (attention): ViTAttention(\n",
       "                (attention): ViTSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (1): ViTLayer(\n",
       "              (attention): ViTAttention(\n",
       "                (attention): ViTSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (2): ViTLayer(\n",
       "              (attention): ViTAttention(\n",
       "                (attention): ViTSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (3): ViTLayer(\n",
       "              (attention): ViTAttention(\n",
       "                (attention): ViTSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (4): ViTLayer(\n",
       "              (attention): ViTAttention(\n",
       "                (attention): ViTSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (5): ViTLayer(\n",
       "              (attention): ViTAttention(\n",
       "                (attention): ViTSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (6): ViTLayer(\n",
       "              (attention): ViTAttention(\n",
       "                (attention): ViTSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (7): ViTLayer(\n",
       "              (attention): ViTAttention(\n",
       "                (attention): ViTSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (8): ViTLayer(\n",
       "              (attention): ViTAttention(\n",
       "                (attention): ViTSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (9): ViTLayer(\n",
       "              (attention): ViTAttention(\n",
       "                (attention): ViTSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (10): ViTLayer(\n",
       "              (attention): ViTAttention(\n",
       "                (attention): ViTSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (11): ViTLayer(\n",
       "              (attention): ViTAttention(\n",
       "                (attention): ViTSelfAttention(\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): ViTSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): ViTIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): ViTOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (pooler): ViTPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=16, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "      (linear): Linear(in_features=34, out_features=16, bias=True)\n",
       "    )\n",
       "    (ode): NeuralODE(\n",
       "      (ode_f): Sequential(\n",
       "        (0): Linear(in_features=16, out_features=1024, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=1024, out_features=16, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (ode_g): Sequential(\n",
       "        (0): Linear(in_features=16, out_features=1024, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=1024, out_features=32, bias=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (barrier): InDCBFBarrier(\n",
       "    (cbf): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (7): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim = 16\n",
    "# barrier = InDCBFAttentionBarrier(2,latent_dim=latent_dim)\n",
    "barrier = InDCBFBarrier(2,latent_dim=latent_dim)\n",
    "model = InDCBFDynamics(2,\"cuda\",model=\"google/vit-base-patch16-224\",latent_dim=latent_dim)\n",
    "# model = InDCBFAttentionDynamics(2,\"cuda\",model=\"google/vit-base-patch16-224\",latent_dim=latent_dim)\n",
    "# model = InDCBFAttentionDynamics(2,\"cuda\",model=\"openai/clip-vit-base-patch16\",latent_dim=latent_dim)\n",
    "# model = InDCBFAttentionDynamics(2,\"cuda\",model=\"resnet50\",latent_dim=latent_dim)\n",
    "# model = InDCBFAttentionDynamics(2,\"cuda\",model=\"vc1\",latent_dim=latent_dim)\n",
    "trainer = InDCBFTrainer(model,barrier)\n",
    "# checkpoint = torch.load(\"/root/tf-logs/InDCBF/version_3/checkpoints/last.ckpt\")\n",
    "checkpoint = torch.load(\"/root/tf-logs/InDCBFUnfused/version_0/checkpoints/last.ckpt\")\n",
    "trainer.load_state_dict(checkpoint['state_dict'])\n",
    "trainer.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.13it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.99it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.72it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.71it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.71it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.72it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.71it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.77it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.78it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.81it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.79it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.79it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.75it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.72it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.70it/s]\n"
     ]
    }
   ],
   "source": [
    "b_all = []\n",
    "label_all = []\n",
    "trainer.eval()\n",
    "for idx, (i,u,label) in enumerate(test_dataloader):\n",
    "    i, u = i.to(\"cuda\"), u.to(\"cuda\")\n",
    "    x,x_tide = trainer.model.simulate(i,u)\n",
    "    b = trainer.barrier(x).squeeze(-1)\n",
    "    b_all.append(b.cpu())\n",
    "    label_all.append(label.squeeze(-1))\n",
    "import numpy as np\n",
    "bs = torch.cat(b_all)\n",
    "labels = torch.cat(label_all)\n",
    "results = torch.cat([bs,labels.unsqueeze(-1)],dim=-1).detach().numpy()\n",
    "np.savetxt(\"./results_indcbfunfused_vit.txt\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9788659793814433 0.2\n"
     ]
    }
   ],
   "source": [
    "results = np.loadtxt(\"./results_indcbfunfused_vit.txt\")\n",
    "regular = results[results[:,-1] == 0,:-1]\n",
    "collision = results[results[:,-1] == 1,:-1]\n",
    "acc_regular = (regular > 0).mean()\n",
    "acc_collision = (collision < 0).mean()\n",
    "print(acc_regular,acc_collision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.54it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.65it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.22it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.63it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.61it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.62it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.65it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.64it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.58it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.63it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.64it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.65it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.63it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.45it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.45it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.41it/s]\n"
     ]
    }
   ],
   "source": [
    "b_all = []\n",
    "label_all = []\n",
    "trainer.eval()\n",
    "for idx, (i,u,label) in enumerate(test_dataloader):\n",
    "    i, u = i.to(\"cuda\"), u.to(\"cuda\")\n",
    "    x,x_tide = trainer.model.simulate(i,u)\n",
    "    b = trainer.barrier(x)\n",
    "    d_b_safe = torch.autograd.grad(b.mean(),x,retain_graph=True)[0]\n",
    "    with torch.no_grad():\n",
    "        f, g = trainer.model.ode(x)\n",
    "    gu = torch.einsum('btha,bta->bth',g.view(g.shape[0],g.shape[1],f.shape[-1],2),u)\n",
    "    ascent_value = torch.einsum('bth,bth->bt', d_b_safe, (f + gu)) + b.squeeze(-1)\n",
    "    b_all.append(ascent_value.cpu())\n",
    "    label_all.append(label.squeeze(-1))\n",
    "bs = torch.cat(b_all)\n",
    "labels = torch.cat(label_all)\n",
    "results = torch.cat([bs,labels.unsqueeze(-1)],dim=-1).detach().numpy()\n",
    "np.savetxt(\"./results_indcbf_grad_resnet.txt\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.35it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.07it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.72it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.75it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.78it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.77it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.78it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.63it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.78it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.50it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.77it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.76it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.77it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.78it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.78it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.16it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.78it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  4.77it/s]\n"
     ]
    }
   ],
   "source": [
    "b_all = []\n",
    "label_all = []\n",
    "trainer.eval()\n",
    "for idx, (i,u,label) in enumerate(test_dataloader):\n",
    "    i, u = i.to(\"cuda\"), u.to(\"cuda\")\n",
    "    x,x_tide = trainer.model.simulate(i,u)\n",
    "    B,T,N,H = x.shape\n",
    "    weight = torch.einsum(\"btnh,btnh->btn\",trainer.barrier.attention.expand(B,T,-1,-1),x)\n",
    "    x_fused = torch.einsum(\"btn,btnh->btnh\",weight,x).sum(2)\n",
    "    b = trainer.barrier.cbf(x_fused)\n",
    "    d_b_safe = torch.autograd.grad(b.mean(),x_fused,retain_graph=True)[0]\n",
    "    with torch.no_grad():\n",
    "        f, g = trainer.model.ode(x)\n",
    "    gu = torch.einsum('btnha,btna->btnh',g.view(g.shape[0],g.shape[1],g.shape[2],f.shape[-1],2),u.unsqueeze(2).expand(-1,-1,g.shape[2],-1))\n",
    "    dx = torch.einsum(\"btn,btnh->btnh\",weight,(f + gu)).sum(2)\n",
    "    ascent_value = torch.einsum('bth,bth->bt', d_b_safe, dx).unsqueeze(-1) + b\n",
    "    b_all.append(ascent_value.cpu())\n",
    "    label_all.append(label.squeeze(-1))\n",
    "bs = torch.cat(b_all)\n",
    "labels = torch.cat(label_all)\n",
    "results = torch.cat([bs.squeeze(-1),labels.unsqueeze(-1)],dim=-1).detach().numpy()\n",
    "np.savetxt(\"./results_indcbfunfused_grad_vit.txt\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9675257731958763 0.32727272727272727\n"
     ]
    }
   ],
   "source": [
    "results = np.loadtxt(\"./results_indcbf_grad_vit.txt\")\n",
    "regular = results[results[:,-1] == 0,:-1]\n",
    "collision = results[results[:,-1] == 1,:-1]\n",
    "acc_regular = (regular > 0).mean()\n",
    "acc_collision = (collision < 0).mean()\n",
    "print(acc_regular,acc_collision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
